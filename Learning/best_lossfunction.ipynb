{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AADI.csv', 'AAPL.csv', 'ABCL.csv', 'ABIO.csv', 'AACG.csv', 'AAL.csv', 'ABEO.csv', 'AAON.csv', 'AACI.csv', 'AAME.csv', 'ABCM.csv', 'ABCB.csv', 'AACIW.csv', 'ABNB.csv', 'AAOI.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mypytable as mypy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "stockfiles= os.listdir(\"/home/cbarker4/Documents/DataScience/StockTrader/Data\")\n",
    "print(stockfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AADI.csv\n",
      "AAPL.csv\n",
      "ABCL.csv\n",
      "ABIO.csv\n",
      "AACG.csv\n",
      "AAL.csv\n",
      "ABEO.csv\n",
      "AAON.csv\n",
      "AACI.csv\n",
      "AAME.csv\n",
      "ABCM.csv\n",
      "ABCB.csv\n",
      "AACIW.csv\n",
      "ABNB.csv\n",
      "AAOI.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = []\n",
    "Y=[]\n",
    "Xlast=[]\n",
    "for val in stockfiles:\n",
    "    print(val)\n",
    "\n",
    "    mt = mypy.MyPyTable()\n",
    "    mt.load_from_file(\"/home/cbarker4/Documents/DataScience/StockTrader/Data/\"+stockfiles[0])\n",
    "    mt.drop_column('v')\n",
    "    mt.drop_column('t')\n",
    "    mt.drop_column('s')\n",
    "    i = 100\n",
    "    while i <  + len(mt.data)-1:\n",
    "        table = mt.create_sub_table(i-100,i)\n",
    "\n",
    "        table.drop_column('v')\n",
    "        table.drop_column('t')\n",
    "        X.append(table.data)\n",
    "        Xlast.append(table.data[-1])\n",
    "        Y.append(mt.get_row(i+1)[0])\n",
    "        i+=1\n",
    "    \n",
    "X = np.array(X)\n",
    "# print(Y)\n",
    "Y = np.array(Y)\n",
    "# print(Y.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.25 ,random_state=0)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'loss',\n",
    "        patience = 7,\n",
    "        verbose = 1,\n",
    "        min_delta = 0,\n",
    "        mode = 'min',\n",
    "        baseline = None,\n",
    "        restore_best_weights = True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(\"/home/cbarker4/Documents/DataScience/StockTrader/Model\", 'ckpt', \"{epoch:02d}-{val_loss:.2f}.hdf5\"),\n",
    "        monitor = 'loss',\n",
    "        verbose = 1,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False,\n",
    "        mode = 'min',\n",
    "        save_freq = 'epoch',\n",
    "        options = None,\n",
    "        initial_value_threshold = None\n",
    "    )   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 14:08:40.098198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2023-04-07 14:08:40.098232: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1554 : UNKNOWN: Fail to find the dnn implementation.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential_4/lstm_8/PartitionedCall]] [Op:__inference_train_function_21957]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m model\u001b[39m.\u001b[39msummary\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m#,metrics=accuracy)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,Y_train,epochs \u001b[39m=\u001b[39;49m \u001b[39m500\u001b[39;49m, \n\u001b[1;32m     18\u001b[0m                                     validation_split \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m, \n\u001b[1;32m     19\u001b[0m                                     callbacks \u001b[39m=\u001b[39;49m callbacks)\n\u001b[1;32m     22\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     23\u001b[0m Xlast\u001b[39m=\u001b[39m[]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential_4/lstm_8/PartitionedCall]] [Op:__inference_train_function_21957]"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_fun=[\"mean_absolute_error\"]\n",
    "\n",
    "for funct in loss_fun:\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=64,\n",
    "                                return_sequences=True,\n",
    "                                input_shape=(X_train.shape[1], 5)))\n",
    "    model.add(tf.keras.layers.LSTM(units=64))\n",
    "    model.add(tf.keras.layers.Dense(32))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    # model.summary\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam',loss = 'mean_absolute_error')#,metrics=accuracy)\n",
    "    history = model.fit(X_train,Y_train,epochs = 500, \n",
    "                                        validation_split = 0.2, \n",
    "                                        callbacks = callbacks)\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    Xlast=[]\n",
    "    correct = 0\n",
    "    for val in X_test:\n",
    "        Xlast.append(val[-1][0])\n",
    "\n",
    "\n",
    "    for i,val in enumerate(Y_test):\n",
    "        \n",
    "        if Xlast[i] > val:\n",
    "            if Xlast[i]>y_pred[i]:\n",
    "                correct+=1\n",
    "        else:\n",
    "            if Xlast[i]<y_pred[i]:\n",
    "                correct+=1 \n",
    "\n",
    "    print('Correct predictions: ', correct)\n",
    "    print('Incorrect predictions: ', len(y_pred) - correct)\n",
    "    print('Accuracy: ', correct / len(y_pred))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57f72d97daca9169f30c9ad42adeb4d6ec91c220776b1e342e1d269fde56f1f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
