{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to get my data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mypytable as mypy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockfiles= os.listdir(\"/home/cbarker4/Documents/DataScience/StockTrader/Data\")\n",
    "# print(stockfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL.csv\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y=[]\n",
    "Xlast=[]\n",
    "stockfiles=[\"AAPL.csv\"]\n",
    "for j,val in enumerate(stockfiles):\n",
    "    print(val)\n",
    "    if j == 30:\n",
    "        break\n",
    "\n",
    "    mt = mypy.MyPyTable()\n",
    "    mt.load_from_file(\"/home/cbarker4/Documents/DataScience/StockTrader/Data/\"+val)\n",
    "    # mt.drop_column('v')\n",
    "    # mt.drop_column('t')\n",
    "    # mt.drop_column('s')\n",
    "    # mt.drop_column('h')\n",
    "    # mt.drop_column('l')\n",
    "    # mt.drop_column('o')\n",
    "\n",
    "    mt.drop_column(0)\n",
    "    i = 100\n",
    "    while i <  len(mt.data)-1:\n",
    "    \n",
    "\n",
    "        table = mt.create_sub_table(i-100,i)\n",
    "        # big = table.max()\n",
    "        # little = table.min()\n",
    "        # table = table.normalize()\n",
    "        \n",
    "\n",
    "      \n",
    "        # print(table.data[0])\n",
    "        X.append(copy.deepcopy(table.get_column(0)))\n",
    "        # Xlast.append(table.data[-1])\n",
    "        # num = int((((mt.get_row(i+1)[0])-little))/(big-little)*1000)/10\n",
    "        num = mt.get_row(i+1)[0]\n",
    "        Y.append(num)\n",
    "        i+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.37\n",
      "154.48\n",
      "0.4864864864864865\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "# print(Y)\n",
    "Y = np.array(Y)\n",
    "# print(Y.shape)\n",
    "count = 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.25 ,random_state=10)\n",
    "i=0\n",
    "for val in X_train:\n",
    "    # print(val[-1][0])\n",
    "    # if val[-1][0]<Y_train[i]:\n",
    "    if val[-1]<Y_train[i]:\n",
    "        count+=1\n",
    "    i+=1\n",
    "\n",
    "print(X_train[-1][-1])\n",
    "print(Y_train[-1])\n",
    "print(count/len(Y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (111, 100)\n",
      "y_train shape:  (111,)\n",
      "X_test shape:  (38, 100)\n",
      "y_test shape:  (38,)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', Y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "\n",
    "    good = abs(y_true-y_pred)\n",
    "    if good>.25:\n",
    "        False\n",
    "    else:\n",
    "        True\n",
    "    \n",
    "\n",
    "\n",
    "# Build epoch checkpoint callback\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=500,\n",
    "        verbose=1,\n",
    "        min_delta = 0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(\"/home/cbarker4/Documents/DataScience/StockTrader/Model\", 'ckpt', \"{epoch:02d}-{loss:.2f}.hdf5\"),\n",
    "        monitor='loss',\n",
    "        verbose = 0,\n",
    "        save_best_only = False,\n",
    "        save_weights_only = False,\n",
    "        mode = 'auto',\n",
    "        save_freq='epoch',\n",
    "        options=None,\n",
    "        initial_value_threshold=None\n",
    "    )   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Ce_Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call (self, y_true,y_pred):\n",
    "        # if y_true[1]:\n",
    "        #     if y_pred>y_true[0]:\n",
    "        ans = tf.math.subtract(y_true[0],y_pred)\n",
    "        ans = tf.math.square(ans)\n",
    "        return tf.math.abs(ans)\n",
    "        #     else:\n",
    "        #         ans = tf.math.subtract(y_true[0],y_pred)\n",
    "        #         ans =  tf.math.abs(ans)\n",
    "        #         return tf.math.square(ans)\n",
    "        # else:\n",
    "        #     if y_pred<y_true[0]:\n",
    "        #         ans = tf.math.subtract(y_true[0],y_pred)\n",
    "        #         return tf.math.abs(ans)\n",
    "        #     else:\n",
    "        #         ans = tf.math.subtract(y_true[0],y_pred)\n",
    "        #         ans =  tf.math.abs(ans)\n",
    "        #         return tf.math.square(ans)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_230 (LSTM)             (None, 100, 64)           16896     \n",
      "                                                                 \n",
      " lstm_231 (LSTM)             (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,033\n",
      "Trainable params: 52,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loss_fun=[\"mean_absolute_error\",\"KLD\",\"MAE\",\"MAPE\",\"MSE\",\"MSLE\",\"binary_crossentropy\",\"binary_focal_crossentropy\",\"binary_crossentropy\",\"binary_focal_crossentropy\",\"categorical_accuracy\",\"categorical crossentropy\",\"deserialize\",\"get\",\"logcosh\",\"hinge\",\"kld\",\"poisson\",\"mse\",\"mean_squared_logarithmic_error\"]\n",
    "# loss_fun = [\"binary_crossentropy\",\"binary_focal_crossentropy\"]\n",
    "# loss_fun = [\"binary_crossentropy\",\"binary_focal_crossentropy\",\"categorical_accuracy\",\"categorical crossentropy\",\"deserialize\"]\n",
    "# loss_fun = [\"mean_squared_logarithmic_error\"]\n",
    "loss_fun = [\"MAE\"]\n",
    "best = {}\n",
    "for losfun in loss_fun:\n",
    "    # break\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=64,\n",
    "                                return_sequences=True,\n",
    "                                input_shape=(X_train.shape[1],1)))\n",
    "    # model.add(tf.keras.layers.LSTM(units=256,return_sequences=True))\n",
    "    model.add(tf.keras.layers.LSTM(64))\n",
    "    model.add(tf.keras.layers.Dense(32))\n",
    "    # model.add(tf.keras.layers.Dense(64))\n",
    "    # model.add(tf.keras.layers.Dense(32))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # print(Y_train)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 2s 13ms/step - loss: 21461.7656\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 20996.7676\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 20400.5898\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 19690.0723\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 18889.2988\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 18213.1230\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 17323.9805\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 16490.2734\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 15627.5781\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 14738.9795\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 13897.0947\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 13067.5537\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 11860.9141\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 11066.7344\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 10412.1602\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 9835.3906\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9296.1650\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8302.4209\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7805.8662\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7057.4893\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6672.7837\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6041.6851\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5440.9702\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4752.9932\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4424.0254\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4045.0940\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3150.3235\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3076.8474\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2725.6731\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2403.8379\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2140.4890\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2194.0061\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2005.5148\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1536.7720\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1239.0950\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1247.7510\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1316.0925\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1329.7274\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 829.2491\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 885.8082\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 909.0526\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 694.8475\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 708.0906\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 861.2082\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 932.1422\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 905.6875\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 849.6596\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 901.3977\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 756.3187\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 837.0251\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 818.1485\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 732.9403\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 783.6159\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 649.2062\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 741.3248\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 633.3987\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 702.2191\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 732.3959\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 894.7771\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 688.4521\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 699.2293\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 713.3121\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 751.9697\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 690.3154\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 652.5814\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 764.4800\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 862.0280\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 861.6766\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 866.6360\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 818.9282\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 706.7896\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 772.1736\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1078.1040\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 817.9199\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 699.1474\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 741.6061\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 731.7969\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 692.2432\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 784.2144\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 908.2064\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1123.4209\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 684.2014\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 661.7072\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 811.8030\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 716.3243\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 780.6752\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 814.6017\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 700.7065\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 760.0378\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 759.7220\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 846.5222\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 874.9980\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1018.8764\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 689.4651\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 684.0273\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 626.7658\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 694.1633\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 698.3286\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 761.7364\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 637.3704\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 670.2692\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 740.8699\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 714.9418\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 620.7598\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 987.2108\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 815.8860\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 733.2339\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 860.3187\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 750.3823\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 695.6741\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 852.5148\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 734.2800\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 739.5005\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 814.6913\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 734.8221\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 637.0299\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 678.3342\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 615.3016\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 820.2352\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 664.4045\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 871.9451\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 807.2960\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 827.6450\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 714.6725\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 905.7849\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 599.2896\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 648.5508\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 866.2590\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 707.1692\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 789.1131\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 778.9316\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 697.1117\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 963.9514\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 845.3607\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 674.5095\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 710.6852\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 733.2827\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 770.7838\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 614.9955\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 750.8989\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 768.8428\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 864.8433\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 815.1578\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 573.5321\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 590.8444\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 671.3041\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 624.3298\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 804.4082\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 683.3386\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 765.1232\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 723.2431\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 740.9677\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 927.3651\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 804.8356\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 687.6177\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 764.7055\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 827.0266\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 860.7550\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 775.0357\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 631.3238\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 875.0021\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 592.9429\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 975.0439\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 529.8014\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 681.6793\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 810.4128\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 802.9453\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 694.3956\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 766.5732\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 662.3293\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 864.8864\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 715.2267\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 623.1765\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 694.7075\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 799.3121\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 761.5739\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 486.0694\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 793.6431\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 659.6332\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 583.7042\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 705.9639\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 747.4449\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 710.9435\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 662.7589\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 710.6802\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 614.4244\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 640.5707\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 660.2818\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 690.4713\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 662.1715\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 753.5139\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 619.9788\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 695.7805\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 590.1860\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 629.8942\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 718.2084\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 883.7417\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 633.0989\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 736.6158\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 790.8438\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 676.0533\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 699.9301\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 559.6864\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 900.8629\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 579.9027\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 672.5703\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 673.5447\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 700.8649\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 794.8605\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 697.9062\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 657.4179\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 763.1957\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 742.7166\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 769.5121\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 794.4362\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 690.0443\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 710.4372\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 706.3043\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 746.3313\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 804.3474\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 683.2042\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 687.9299\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 702.6550\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 839.9484\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 769.5505\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 711.2682\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 636.4734\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 721.9235\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 821.4866\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 804.3442\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 790.1851\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 668.4435\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 619.2474\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 708.4932\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 914.0527\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 718.0218\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 705.5965\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 726.1235\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 654.4421\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 643.2758\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 772.3751\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 700.3455\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 813.1656\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 840.6215\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 716.6879\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 753.1194\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 774.8055\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 841.0964\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 672.1435\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 779.1879\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 771.2389\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 745.6790\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 735.5336\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 608.0102\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 806.4208\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 559.2497\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 878.7947\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 640.9333\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 754.6948\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 598.1119\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 786.6432\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 626.1054\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 603.2029\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 518.6642\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 723.2395\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 767.1864\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 631.6379\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 633.7816\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 875.8755\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 782.4010\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 609.7418\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 671.3177\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 813.2335\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 792.0111\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 804.8157\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 652.3464\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 733.2367\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 623.1437\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 718.0782\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 914.3688\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 759.6058\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 657.6342\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 748.2923\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 810.7261\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 659.8019\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 671.5505\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 713.2247\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 820.5477\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 837.6370\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 781.3945\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 734.5582\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 766.2551\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 686.8819\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 844.0389\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 636.3842\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 615.6011\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 697.1803\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 838.0472\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 710.1797\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 647.0445\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 657.4144\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 848.3185\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 668.7304\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 635.5574\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 664.1694\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 761.0165\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 556.8781\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 824.8486\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 613.7526\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 805.8964\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 867.8970\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 673.2393\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 827.3162\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 677.4264\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 676.4502\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 799.7463\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 962.9260\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 714.2832\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 805.6659\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 670.1771\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 582.9384\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 665.5693\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 687.5539\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 752.9145\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 822.0493\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 675.8718\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 681.7612\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 793.0804\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 796.7231\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 708.3657\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 765.6061\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 652.7690\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 777.5307\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 764.9362\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 600.1608\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 689.9720\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 727.7411\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 645.2896\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 851.0385\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 982.5445\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 746.8239\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 657.3341\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 571.7510\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 744.3173\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 680.7927\n",
      "Epoch 346/1000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 822.3496"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n",
    "model.fit(X_train,Y_train,epochs=1000, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[124.78445 ]\n",
      " [142.37645 ]\n",
      " [141.13268 ]\n",
      " [126.242485]\n",
      " [140.52933 ]\n",
      " [139.5753  ]\n",
      " [141.45914 ]\n",
      " [126.79354 ]\n",
      " [137.10976 ]\n",
      " [148.43422 ]\n",
      " [148.13646 ]\n",
      " [145.60222 ]\n",
      " [135.76834 ]\n",
      " [144.30215 ]\n",
      " [135.71251 ]\n",
      " [143.32448 ]\n",
      " [126.23312 ]\n",
      " [140.63069 ]\n",
      " [134.74687 ]\n",
      " [138.59497 ]\n",
      " [136.20602 ]\n",
      " [139.63004 ]\n",
      " [139.96138 ]\n",
      " [137.63286 ]\n",
      " [134.12299 ]\n",
      " [143.46051 ]\n",
      " [124.407875]\n",
      " [146.36311 ]\n",
      " [135.64096 ]\n",
      " [124.543335]\n",
      " [142.10228 ]\n",
      " [137.4646  ]\n",
      " [136.77147 ]\n",
      " [141.20082 ]\n",
      " [136.688   ]\n",
      " [133.2855  ]\n",
      " [134.21478 ]\n",
      " [137.2618  ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.04 129.93 [124.78445]\n",
      "152.59 155.85 [142.37645]\n",
      "150.7 156.9 [141.13268]\n",
      "129.62 130.73 [126.242485]\n",
      "150.04 150.72 [140.52933]\n",
      "148.01 151.07 [139.5753]\n",
      "151.07 144.22 [141.45914]\n",
      "129.93 126.36 [126.79354]\n",
      "144.8 153.34 [137.10976]\n",
      "165.63 164.66 [148.43422]\n",
      "Correct predictions:  16\n",
      "Incorrect predictions:  22\n",
      "No change Correct: 0\n",
      "Accuracy:  0.42105263157894735\n",
      "Accuracy:  0.42105263157894735\n",
      "False Pos: 22\n",
      "Pos: 38\n",
      "Pos Accuracy 0.42105263157894735\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[979], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPos Accuracy\u001b[39m\u001b[39m'\u001b[39m,(pos\u001b[39m-\u001b[39mfalsepos)\u001b[39m/\u001b[39mpos)\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(neg)\n\u001b[0;32m---> 45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNeg Accuracy\u001b[39m\u001b[39m'\u001b[39m,(neg\u001b[39m-\u001b[39;49mfalseneg)\u001b[39m/\u001b[39;49mneg)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "Xlast=[]\n",
    "correct = 0\n",
    "for val in X_test:\n",
    "    Xlast.append(val[-1])\n",
    "\n",
    "\n",
    "correct = 0\n",
    "removed = 0\n",
    "falsepos = 0\n",
    "pos = 0\n",
    "neg=0\n",
    "falseneg =0\n",
    "for i,val in enumerate(Y_test):\n",
    "    if i < 10:\n",
    "        print(Xlast[i],Y_test[i],y_pred[i])\n",
    "    if Xlast[i]!=y_pred[i]:\n",
    "        if Xlast[i] > val:\n",
    "\n",
    "            if Xlast[i]>y_pred[i]:\n",
    "                pos+=1\n",
    "                correct+=1\n",
    "            else :\n",
    "                neg+=1\n",
    "                falseneg+=1\n",
    "        \n",
    "        else:\n",
    "            if Xlast[i]<y_pred[i]:\n",
    "                correct+=1 \n",
    "                neg+=1\n",
    "            else:\n",
    "                pos+=1\n",
    "                falsepos+=1\n",
    "    else:\n",
    "        removed+=1\n",
    "\n",
    "print('Correct predictions: ', correct)\n",
    "print('Incorrect predictions: ', (len(y_pred)-removed) - correct)\n",
    "print('Accuracy: ', correct / (len(y_pred)-removed))\n",
    "print('False Pos:',falsepos)\n",
    "print('Pos:',pos)\n",
    "print('Pos Accuracy',(pos-falsepos)/pos)\n",
    "print('Neg:',neg)\n",
    "print('Neg Accuracy',(neg-falseneg)/neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57f72d97daca9169f30c9ad42adeb4d6ec91c220776b1e342e1d269fde56f1f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
